"use strict";(self.webpackChunkjavascript_parser_in_rust=self.webpackChunkjavascript_parser_in_rust||[]).push([[417],{2698:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>c,toc:()=>d});var t=r(1527),s=r(7660);const i={id:"lexer",title:"Lexer"},a=void 0,c={id:"lexer",title:"Lexer",description:"Token",source:"@site/i18n/zh/docusaurus-plugin-content-docs/current/lexer.md",sourceDirName:".",slug:"/lexer",permalink:"/javascript-parser-in-rust/zh/docs/lexer",draft:!1,unlisted:!1,editUrl:"https://github.com/oxc-project/javascript-parser-in-rust/tree/main/docs/lexer.md",tags:[],version:"current",frontMatter:{id:"lexer",title:"Lexer"},sidebar:"tutorialSidebar",previous:{title:"\u603b\u89c8",permalink:"/javascript-parser-in-rust/zh/docs/overview"},next:{title:"Abstract Syntax Tree",permalink:"/javascript-parser-in-rust/zh/docs/ast"}},o={},d=[{value:"Token",id:"token",level:2},{value:"Peek",id:"peek",level:2},{value:"JavaScript",id:"javascript",level:2},{value:"Comments",id:"comments",level:3},{value:"Identifiers and Unicode",id:"identifiers-and-unicode",level:3},{value:"Keywords",id:"keywords",level:3},{value:"Token Value",id:"token-value",level:3},{value:"Rust Optimizations",id:"rust-optimizations",level:2},{value:"Smaller Tokens",id:"smaller-tokens",level:3},{value:"String Interning",id:"string-interning",level:3}];function l(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.h2,{id:"token",children:"Token"}),"\n",(0,t.jsx)(n.p,{children:"The lexer, also known as tokenizer or scanner, is responsible for transforming source text into tokens.\nThe tokens will later be consumed by the parser so we don't have to worry about whitespaces and comments from the original text."}),"\n",(0,t.jsxs)(n.p,{children:["Let's start simple and transform a single ",(0,t.jsx)(n.code,{children:"+"})," text into a token."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"#[derive(Debug, Clone, Copy, PartialEq)]\npub struct Token {\n    /// Token Type\n    pub kind: Kind,\n\n    /// Start offset in source\n    pub start: usize,\n\n    /// End offset in source\n    pub end: usize,\n}\n\n#[derive(Debug, Clone, Copy, PartialEq)]\npub enum Kind {\n    Eof, // end of file\n    Plus,\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["A single ",(0,t.jsx)(n.code,{children:"+"})," gives us"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[\n    Token { kind: Kind::Plus, start: 0, end: 1 },\n    Token { kind: Kind::Eof,  start: 1, end: 1 }\n]\n"})}),"\n",(0,t.jsxs)(n.p,{children:["To loop through the string, we can either keep track of an index and pretend that we are writing C code,\nor we can take a look at the ",(0,t.jsx)(n.a,{href:"https://doc.rust-lang.org/std/primitive.str.html#",children:"string documentation"}),"\nand find ourselves a ",(0,t.jsx)(n.a,{href:"https://doc.rust-lang.org/std/str/struct.Chars.html",children:(0,t.jsx)(n.code,{children:"Chars"})})," iterator to work with."]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"Chars"})," iterator abstracts away the tracking index and boundary checking to make us feel truly safe."]}),(0,t.jsxs)(n.p,{children:["It gives us an ",(0,t.jsx)(n.code,{children:"Option<char>"})," when we call ",(0,t.jsx)(n.code,{children:"chars.next()"}),".\nBut please note that a ",(0,t.jsx)(n.code,{children:"char"})," is not a 0-255 ASCII value,\nit is a utf8 Unicode point value with the range of 0 to 0x10FFFF."]})]}),"\n",(0,t.jsx)(n.p,{children:"Let's define a starter lexer abstraction"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"use std::str::Chars;\n\nstruct Lexer<'a> {\n    /// Source Text\n    source: &'a str,\n\n    /// The remaining characters\n    chars: Chars<'a>\n}\n\nimpl<'a> Lexer<'a> {\n    pub fn new(source: &'a str) -> Self {\n        Self {\n            source,\n            chars: source.chars()\n        }\n    }\n}\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.p,{children:["The lifetime ",(0,t.jsx)(n.code,{children:"'a"})," here indicates the iterator has a reference to somewhere, it references to a ",(0,t.jsx)(n.code,{children:"&'a str"})," in this case."]})}),"\n",(0,t.jsxs)(n.p,{children:["To convert the source text to tokens, just keep calling ",(0,t.jsx)(n.code,{children:"chars.next()"})," and match on the returned ",(0,t.jsx)(n.code,{children:"char"}),"s.\nThe final token will always be ",(0,t.jsx)(n.code,{children:"Kind::Eof"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"impl<'a> Lexer<'a> {\n    fn read_next_kind(&mut self) -> Kind {\n        while let Some(c) = self.chars.next() {\n            match c {\n              '+' => return Kind::Plus,\n              _ => {}\n            }\n        }\n        Kind::Eof\n    }\n\n    fn read_next_token(&mut self) -> Token {\n        let start = self.offset();\n        let kind = self.read_next_kind();\n        let end = self.offset();\n        Token { kind, start, end }\n    }\n\n    /// Get the length offset from the source text, in UTF-8 bytes\n    fn offset(&self) -> usize {\n        self.source.len() - self.chars.as_str().len()\n    }\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:".len()"})," and ",(0,t.jsx)(n.code,{children:".as_str().len()"})," method calls inside ",(0,t.jsx)(n.code,{children:"fn offset"})," feel like O(n), so let's dig deeper."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://doc.rust-lang.org/src/core/str/iter.rs.html#112",children:(0,t.jsx)(n.code,{children:".as_str()"})})," returns a pointer to a string slice"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",metastring:"reference",children:"https://github.com/rust-lang/rust/blob/b998821e4c51c44a9ebee395c91323c374236bbb/library/core/src/str/iter.rs#L112-L115\n"})}),"\n",(0,t.jsxs)(n.p,{children:["A ",(0,t.jsx)(n.a,{href:"https://doc.rust-lang.org/std/slice/index.html",children:"slice"})," is a view into a block of memory represented as a pointer and a length.\nThe ",(0,t.jsx)(n.code,{children:".len()"})," method returns the meta data stored inside the slice"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",metastring:"reference",children:"https://github.com/rust-lang/rust/blob/b998821e4c51c44a9ebee395c91323c374236bbb/library/core/src/str/mod.rs#L157-L159\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",metastring:"reference",children:"https://github.com/rust-lang/rust/blob/b998821e4c51c44a9ebee395c91323c374236bbb/library/core/src/str/mod.rs#L323-L325\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",metastring:"reference",children:"https://github.com/rust-lang/rust/blob/b998821e4c51c44a9ebee395c91323c374236bbb/library/core/src/slice/mod.rs#L129-L138\n"})}),"\n",(0,t.jsxs)(n.p,{children:["All the above code will get compiled into a single data access, so ",(0,t.jsx)(n.code,{children:".as_str().len()"})," is actually O(1)."]}),"\n",(0,t.jsx)(n.h2,{id:"peek",children:"Peek"}),"\n",(0,t.jsxs)(n.p,{children:["To tokenize multi-character operators such as ",(0,t.jsx)(n.code,{children:"++"})," or ",(0,t.jsx)(n.code,{children:"+="}),", a helper function ",(0,t.jsx)(n.code,{children:"peek"})," is required:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"fn peek(&self) -> Option<char> {\n    self.chars.clone().next()\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["We don't want to advance the original ",(0,t.jsx)(n.code,{children:"chars"})," iterator so we clone the iterator and advance the index."]}),"\n",(0,t.jsxs)(n.admonition,{type:"info",children:[(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.code,{children:"clone"})," is cheap if we dig into the ",(0,t.jsx)(n.a,{href:"https://doc.rust-lang.org/src/core/slice/iter.rs.html#148-152",children:"source code"}),",\nit just copies the tracking and boundary index."]}),(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",metastring:"reference",children:"https://github.com/rust-lang/rust/blob/b998821e4c51c44a9ebee395c91323c374236bbb/library/core/src/slice/iter.rs#L148-L152\n"})})]}),"\n",(0,t.jsxs)(n.p,{children:["The difference between ",(0,t.jsx)(n.code,{children:"peek"})," and ",(0,t.jsx)(n.code,{children:"chars.next()"})," is the former will always return the ",(0,t.jsx)(n.strong,{children:"same"})," next ",(0,t.jsx)(n.code,{children:"char"}),",\nwhile the later will move forward and return a different ",(0,t.jsx)(n.code,{children:"char"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["To demonstrate, consider the string ",(0,t.jsx)(n.code,{children:"abc"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["repeated ",(0,t.jsx)(n.code,{children:"peek()"})," call returns ",(0,t.jsx)(n.code,{children:"Some(a)"}),", ",(0,t.jsx)(n.code,{children:"Some(a)"}),", ",(0,t.jsx)(n.code,{children:"Some(a)"}),", ..."]}),"\n",(0,t.jsxs)(n.li,{children:["repeated ",(0,t.jsx)(n.code,{children:"chars.next()"})," call returns ",(0,t.jsx)(n.code,{children:"Some('a')"}),", ",(0,t.jsx)(n.code,{children:"Some('b')"}),", ",(0,t.jsx)(n.code,{children:"Some('c')"}),", ",(0,t.jsx)(n.code,{children:"None"}),"."]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Equipped with ",(0,t.jsx)(n.code,{children:"peek"}),", tokenizing ",(0,t.jsx)(n.code,{children:"++"})," and ",(0,t.jsx)(n.code,{children:"+="})," are just nested if statements."]}),"\n",(0,t.jsxs)(n.p,{children:["Here is a real-world implementation from ",(0,t.jsx)(n.a,{href:"https://github.com/mozilla-spidermonkey/jsparagus",children:"jsparagus"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",metastring:"reference",children:"https://github.com/mozilla-spidermonkey/jsparagus/blob/master/crates/parser/src/lexer.rs#L1769-L1791\n"})}),"\n",(0,t.jsx)(n.p,{children:"The above logic applies to all operators, so let us expand our knowledge on lexing JavaScript."}),"\n",(0,t.jsx)(n.h2,{id:"javascript",children:"JavaScript"}),"\n",(0,t.jsxs)(n.p,{children:["A lexer written in Rust is rather boring, it feels like writing C code\nwhere we write long chained if statements and check for each ",(0,t.jsx)(n.code,{children:"char"})," and then return the respective token."]}),"\n",(0,t.jsx)(n.p,{children:"The real fun begins when we start lexing for JavaScript."}),"\n",(0,t.jsxs)(n.p,{children:["Let's open up the ",(0,t.jsx)(n.a,{href:"https://tc39.es/ecma262/",children:"ECMAScript Language Specification"})," and re-learn JavaScript."]}),"\n",(0,t.jsx)(n.admonition,{type:"caution",children:(0,t.jsxs)(n.p,{children:["I still remember the first time I opened up the specification and went into a little corner\nand cried in agony because it feels like reading foreign text with jargons everywhere.\nSo head over to my ",(0,t.jsx)(n.a,{href:"/blog/ecma-spec",children:"guide on reading the specification"})," if things don't make sense."]})}),"\n",(0,t.jsx)(n.h3,{id:"comments",children:"Comments"}),"\n",(0,t.jsx)(n.p,{children:"Comments have no semantic meaning, they can be skipped if we are writing a runtime,\nbut they need to be taken into consideration if we are writing a linter or a bundler."}),"\n",(0,t.jsx)(n.h3,{id:"identifiers-and-unicode",children:"Identifiers and Unicode"}),"\n",(0,t.jsxs)(n.p,{children:["We mostly code in ASCII,\nbut ",(0,t.jsx)(n.a,{href:"https://tc39.es/ecma262/#sec-ecmascript-language-source-code",children:"Chapter 11 ECMAScript Language: Source Text"}),"\nstates the source text should be in Unicode.\nAnd ",(0,t.jsx)(n.a,{href:"https://tc39.es/ecma262/#sec-names-and-keywords",children:"Chapter 12.6 Names and Keywords"}),"\nstates the identifiers are interpreted according to the Default Identifier Syntax given in Unicode Standard Annex #31.\nIn detail:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-markup",children:"IdentifierStartChar ::\n    UnicodeIDStart\n\nIdentifierPartChar ::\n    UnicodeIDContinue\n\nUnicodeIDStart ::\n    any Unicode code point with the Unicode property \u201cID_Start\u201d\n\nUnicodeIDContinue ::\n    any Unicode code point with the Unicode property \u201cID_Continue\u201d\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This means that we can write ",(0,t.jsx)(n.code,{children:"var \u0ca0_\u0ca0"})," but not ",(0,t.jsx)(n.code,{children:"var \ud83e\udd80"}),",\n",(0,t.jsx)(n.code,{children:"\u0ca0"}),' has the Unicode property "ID_Start" while ',(0,t.jsx)(n.code,{children:"\ud83e\udd80"})," does not."]}),"\n",(0,t.jsx)(n.admonition,{type:"info",children:(0,t.jsxs)(n.p,{children:["I published the ",(0,t.jsx)(n.a,{href:"https://crates.io/crates/unicode-id-start",children:"unicode-id-start"})," crate for this exact purpose.\n",(0,t.jsx)(n.code,{children:"unicode_id_start::is_id_start(char)"})," and ",(0,t.jsx)(n.code,{children:"unicode_id_start::is_id_continue(char)"})," can be called to check Unicode."]})}),"\n",(0,t.jsx)(n.h3,{id:"keywords",children:"Keywords"}),"\n",(0,t.jsxs)(n.p,{children:["All the ",(0,t.jsx)(n.a,{href:"https://tc39.es/ecma262/#sec-keywords-and-reserved-words",children:"keywords"})," such as ",(0,t.jsx)(n.code,{children:"if"}),", ",(0,t.jsx)(n.code,{children:"while"})," and ",(0,t.jsx)(n.code,{children:"for"}),"\nneed to be tokenized and interpreted as a whole.\nThey need to be added to the token kind enum so we don't have to make string comparisons in the parser."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"pub enum Kind {\n    Identifier,\n    If,\n    While,\n    For\n}\n"})}),"\n",(0,t.jsx)(n.admonition,{type:"caution",children:(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.code,{children:"undefined"})," is not a keyword, it is unnecessary to add it here."]})}),"\n",(0,t.jsx)(n.p,{children:"Tokenizing keywords will just be matching the identifier from above."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:'fn match_keyword(&self, ident: &str) -> Kind {\n    // all keywords are 1 <= length <= 10\n    if ident.len() == 1 || ident.len() > 10 {\n        return Kind::Identifier;\n    }\n    match ident {\n        "if" => Kind::If,\n        "while" => Kind::While,\n        "for" => Kind::For,\n        _ => Kind::Identifier\n    }\n}\n'})}),"\n",(0,t.jsx)(n.h3,{id:"token-value",children:"Token Value"}),"\n",(0,t.jsx)(n.p,{children:"We often need to compare identifiers, numbers and strings in later stages of the compiler phases,\nfor example testing against identifiers inside a linter,"}),"\n",(0,t.jsx)(n.p,{children:"These values are currently in plain source text,\nlet's convert them to Rust types so they are easier to work with."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"pub enum Kind {\n    Eof, // end of file\n    Plus,\n    // highlight-start\n    Identifier,\n    Number,\n    String,\n    // highlight-end\n}\n\n#[derive(Debug, Clone, Copy, PartialEq)]\npub struct Token {\n    /// Token Type\n    pub kind: Kind,\n\n    /// Start offset in source\n    pub start: usize,\n\n    /// End offset in source\n    pub end: usize,\n\n    // highlight-next-line\n    pub value: TokenValue,\n}\n\n#[derive(Debug, Clone, PartialEq)]\npub enum TokenValue {\n    None,\n    Number(f64),\n    String(String),\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["When an identifier ",(0,t.jsx)(n.code,{children:"foo"})," or string ",(0,t.jsx)(n.code,{children:'"bar"'})," is tokenized , we get"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-markup",children:'Token { kind: Kind::Identifier, start: 0, end: 2, value: TokenValue::String("foo") }\nToken { kind: Kind::String, start: 0, end: 4, value: TokenValue::String("bar") }\n'})}),"\n",(0,t.jsxs)(n.p,{children:["To convert them to Rust strings, call ",(0,t.jsx)(n.code,{children:"let s = self.source[token.start..token.end].to_string()"}),"\nand save it with ",(0,t.jsx)(n.code,{children:"token.value = TokenValue::String(s)"}),"."]}),"\n",(0,t.jsxs)(n.p,{children:["When we tokenized a number ",(0,t.jsx)(n.code,{children:"1.23"}),", we get a token with ",(0,t.jsx)(n.code,{children:"Token { start: 0, end: 3 }"}),".\nTo convert it to Rust ",(0,t.jsx)(n.code,{children:"f64"}),", we can use the string ",(0,t.jsx)(n.a,{href:"https://doc.rust-lang.org/std/primitive.str.html#method.parse",children:(0,t.jsx)(n.code,{children:"parse"})}),"\nmethod by calling ",(0,t.jsx)(n.code,{children:"self.source[token.start..token.end].parse::<f64>()"}),", and then save the value into ",(0,t.jsx)(n.code,{children:"token.value"}),".\nFor binary, octal and integers, an example of their parsing techniques can be found in ",(0,t.jsx)(n.a,{href:"https://github.com/mozilla-spidermonkey/jsparagus/blob/master/crates/parser/src/numeric_value.rs",children:"jsparagus"}),"."]}),"\n",(0,t.jsx)(n.h2,{id:"rust-optimizations",children:"Rust Optimizations"}),"\n",(0,t.jsx)(n.h3,{id:"smaller-tokens",children:"Smaller Tokens"}),"\n",(0,t.jsxs)(n.p,{children:["It is tempting to put the token values inside the ",(0,t.jsx)(n.code,{children:"Kind"})," enum and aim for simpler and safer code:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"pub enum Kind {\n    Number(f64),\n    String(String),\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["But it is known that the byte size of a Rust enum is the union of all its variants.\nThis enum packs a lot of bytes compared to the original enum, which has only 1 byte.\nThere will be heavy usages of this ",(0,t.jsx)(n.code,{children:"Kind"})," enum in the parser,\ndealing with a 1 byte enum will obviously be faster than a multi-byte enum."]}),"\n",(0,t.jsx)(n.h3,{id:"string-interning",children:"String Interning"}),"\n",(0,t.jsxs)(n.p,{children:["It is not performant to use ",(0,t.jsx)(n.code,{children:"String"})," in compilers, mainly due to:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"String"})," is a heap allocated object"]}),"\n",(0,t.jsx)(n.li,{children:"String comparison is an O(n) operation"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.a,{href:"https://en.wikipedia.org/wiki/String_interning",children:"String Interning"})," solves these problems by\nstoring only one copy of each distinct string value with a unique identifier in a cache.\nThere will only be one heap allocation per distinct identifier or string, and string comparisons become O(1)."]}),"\n",(0,t.jsxs)(n.p,{children:["There are lots of string interning libraries on ",(0,t.jsx)(n.a,{href:"https://crates.io/search?q=string%20interning",children:"crates.io"}),"\nwith different pros and cons."]}),"\n",(0,t.jsxs)(n.p,{children:["A sufficient starting point is to use ",(0,t.jsx)(n.a,{href:"https://crates.io/crates/string_cache",children:(0,t.jsx)(n.code,{children:"string-cache"})}),",\nit has an ",(0,t.jsx)(n.code,{children:"Atom"})," type and a compile time ",(0,t.jsx)(n.code,{children:'atom!("string")'})," interface."]}),"\n",(0,t.jsxs)(n.p,{children:["With ",(0,t.jsx)(n.code,{children:"string-cache"}),", ",(0,t.jsx)(n.code,{children:"TokenValue"})," becomes"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-rust",children:"#[derive(Debug, Clone, PartialEq)]\npub enum TokenValue {\n    None,\n    Number(f64),\n    // highlight-next-line\n    String(Atom),\n}\n"})}),"\n",(0,t.jsxs)(n.p,{children:["and string comparison becomes ",(0,t.jsx)(n.code,{children:'matches!(value, TokenValue::String(atom!("string")))'}),"."]})]})}function h(e={}){const{wrapper:n}={...(0,s.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(l,{...e})}):l(e)}},7660:(e,n,r)=>{r.d(n,{Z:()=>c,a:()=>a});var t=r(959);const s={},i=t.createContext(s);function a(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);